{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<style>\n",
    ".container { width:100% }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".container { width:100% }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".container { width:100% }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".container { width:100% }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run othello_game.ipynb\n",
    "%run othello_ai.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ermitteln der Standardabweichung\n",
    "Im Folgenden werden zunächst einige Datenpunkte gesammelt, indem in verschiedenen Spielzuständen jeweils eine tiefe und eine flache Suche durchgeführt wird. Die Spielzustände werden durch zufälliges Ziehen erreicht. Die Daten werden in einer CSV-Datei gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "\n",
    "def sample_probcut_values(num_games, shallow_depth, deep_depth):\n",
    "    fname = f'probcut_dataset_{PROBCUT_SHALLOW_DEPTH}_{PROBCUT_DEEP_DEPTH}.csv'\n",
    "    file_exists = os.path.isfile(fname)\n",
    "    if file_exists:\n",
    "        print('using existing dataset')\n",
    "    else:\n",
    "        with open(fname, 'w', newline='') as file:\n",
    "            writer = csv.writer(file, delimiter=',')\n",
    "            writer.writerow(('moves', 'shallow', 'deep'))\n",
    "            for i in range(num_games):\n",
    "                state = GameState()\n",
    "                while not state.game_over:\n",
    "                    state = ai_make_move(random_ai, state, 0, None)\n",
    "                    shallow_value = alphabeta(\n",
    "                        state, PROBCUT_SHALLOW_DEPTH,\n",
    "                        combined_heuristic, -math.inf, math.inf\n",
    "                    )\n",
    "                    deep_value = alphabeta(\n",
    "                        state, PROBCUT_DEEP_DEPTH,\n",
    "                        combined_heuristic, -math.inf, math.inf\n",
    "                    )\n",
    "                    print(f'shallow: {shallow_value}, deep: {deep_value}')\n",
    "                    writer.writerow(\n",
    "                        (state.num_pieces, shallow_value, deep_value))\n",
    "            file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_probcut_values(100, PROBCUT_SHALLOW_DEPTH, PROBCUT_DEEP_DEPTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Laden der Daten aus der CSV-Datei mithilfe von Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "filename = f'probcut_dataset_{PROBCUT_SHALLOW_DEPTH}_{PROBCUT_DEEP_DEPTH}.csv'\n",
    "df = pandas.read_csv(filename)\n",
    "shallow = np.array(df['shallow'])\n",
    "deep = np.array(df['deep'])\n",
    "moves = np.array(df['moves'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daten Visualisieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sklearn.linear_model as lm\n",
    "import seaborn as sns\n",
    "model = lm.LinearRegression()\n",
    "model.fit(shallow.reshape(len(shallow), 1), deep)\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.set(style='whitegrid')\n",
    "plt.scatter(shallow, deep)\n",
    "plt.axvline(x=0.0, c='k')\n",
    "plt.axhline(y=0.0, c='k')\n",
    "plt.plot(shallow, shallow * model.coef_ + model.intercept_)\n",
    "plt.xlabel('shallow search')\n",
    "plt.ylabel('deep search')\n",
    "plt.title('Probcut Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Folgender Code berechnet die Standardabweichung pro Anzahl Steine auf dem Spielfeld. Dazu werden zunächst für jede Anzahl an Steinen aus den Daten die passenden Werte extrahiert. Für diese Teilmengen wird jeweils die Varianz mit $numpy$ berechnet. Die Standardabweichung ist die positive Wurzel aus der Varianz. Die Anzahl an Steinen und die Standardabweichung werden an entsprechende Felder angehängt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5: Var=0.00019, explained: 0.938\n",
      "6: Var=0.00039, explained: 0.786\n",
      "7: Var=0.00154, explained: 0.932\n",
      "8: Var=0.0009, explained: 0.693\n",
      "9: Var=0.0021, explained: 0.877\n",
      "10: Var=0.00206, explained: 0.864\n",
      "11: Var=0.00296, explained: 0.924\n",
      "12: Var=0.00352, explained: 0.936\n",
      "13: Var=0.0034, explained: 0.948\n",
      "14: Var=0.00436, explained: 0.953\n",
      "15: Var=0.00478, explained: 0.959\n",
      "16: Var=0.00424, explained: 0.961\n",
      "17: Var=0.00519, explained: 0.955\n",
      "18: Var=0.00515, explained: 0.967\n",
      "19: Var=0.00545, explained: 0.957\n",
      "20: Var=0.00547, explained: 0.969\n",
      "21: Var=0.00569, explained: 0.967\n",
      "22: Var=0.00601, explained: 0.968\n",
      "23: Var=0.00549, explained: 0.949\n",
      "24: Var=0.00601, explained: 0.96\n",
      "25: Var=0.00643, explained: 0.96\n",
      "26: Var=0.00679, explained: 0.961\n",
      "27: Var=0.00693, explained: 0.968\n",
      "28: Var=0.00661, explained: 0.964\n",
      "29: Var=0.00653, explained: 0.964\n",
      "30: Var=0.00735, explained: 0.967\n",
      "31: Var=0.0075, explained: 0.954\n",
      "32: Var=0.00847, explained: 0.959\n",
      "33: Var=0.00733, explained: 0.943\n",
      "34: Var=0.00769, explained: 0.956\n",
      "35: Var=0.00722, explained: 0.934\n",
      "36: Var=0.00794, explained: 0.962\n",
      "37: Var=0.00686, explained: 0.921\n",
      "38: Var=0.00781, explained: 0.954\n",
      "39: Var=0.00775, explained: 0.947\n",
      "40: Var=0.00863, explained: 0.956\n",
      "41: Var=0.00883, explained: 0.92\n",
      "42: Var=0.0096, explained: 0.953\n",
      "43: Var=0.00909, explained: 0.932\n",
      "44: Var=0.01003, explained: 0.939\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sklearn.metrics as skl\n",
    "import sklearn.linear_model as lm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for i in range(5, 45):\n",
    "    shallow_c = shallow[moves == i]\n",
    "    deep_c = deep[moves == i]\n",
    "    variance = np.var(np.stack([shallow_c, deep_c], axis=1))\n",
    "    explained_variance = skl.explained_variance_score(shallow_c, deep_c)\n",
    "    x.append(i)\n",
    "    y.append(math.sqrt(variance))\n",
    "    #print(f'{i}: Var={round(variance, 5)}, explained: {round(explained_variance, 3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Folgender Code berechnet die Regressionsgerade der Standardabweichung in Abhängigkeit von der Anzahl der Steine auf dem Spielfeld mit $sklearn$ und stellt diese grafisch  dar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lm.LinearRegression()\n",
    "model.fit(np.array(x).reshape(-1, 1), np.array(y))\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.set(style='whitegrid')\n",
    "plt.scatter(X, y)\n",
    "plt.axvline(x=0.0, c='k')\n",
    "plt.axhline(y=0.0, c='k')\n",
    "plt.plot(x, x * model.coef_ + model.intercept_)\n",
    "plt.xlabel('number of disks on the board')\n",
    "plt.ylabel('standard deviation')\n",
    "plt.title('Standard Deviation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ausgeben der Funktion der Regressionsgerade, welche die Standardabweichung in Abhängigkeit von der Anzahl an Spielsteinen auf dem Spielfeld berechnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('x *', model.coef_[0], '+', model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Varianz, erklärte Varianz und Standardabweichung berechnen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.metrics as skl\n",
    "variance = np.var(np.stack([shallow, deep], axis=1))\n",
    "print(f'variance: {variance}')\n",
    "explained_variance = skl.explained_variance_score(shallow, deep)\n",
    "print(f'standard distribution: {np.sqrt(variance)}')\n",
    "print(f'explained variance: {explained_variance}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
